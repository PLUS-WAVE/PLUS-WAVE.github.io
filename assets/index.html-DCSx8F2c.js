import{_ as n,c as t,a as s,e as h,b as a,d as l,w as p,r as d,o as k}from"./app-CGJJd-cj.js";const r={};function o(c,i){const e=d("RouteLink");return k(),t("div",null,[i[2]||(i[2]=s("h2",{id:"_1-11-1-tiny-cuda-nn",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_1-11-1-tiny-cuda-nn"},[s("span",null,"1.11.1 tiny-cuda-nn")])],-1)),s("p",null,[i[1]||(i[1]=a("tiny-cuda-nn 的编译问题见 ")),l(e,{to:"/experience/a5k8sy7u/#_1-2-7-ld-cannot-find-lcuda"},{default:p(()=>i[0]||(i[0]=[a("1.2.7 ld: cannot find -lcuda")])),_:1})]),i[3]||(i[3]=h(`<h2 id="_1-11-2-cuda-版本不匹配" tabindex="-1"><a class="header-anchor" href="#_1-11-2-cuda-版本不匹配"><span>1.11.2 CUDA 版本不匹配</span></a></h2><p>在使用 <code>pip install -e .</code> / <code>python setup.py develop</code> 安装 <code>map4d</code> 或其他依赖 PyTorch C++/CUDA 扩展的包时，遇到了以下的错误：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">RuntimeError:</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">The</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> detected</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> CUDA</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> version</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> (11.8) mismatches the version that was used to compile</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">PyTorch</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> (12.4). Please make sure to use the same CUDA versions.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><p><strong>排查：</strong></p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">nvcc</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --version</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">python</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -c</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">import torch; print(f&#39;PyTorch version: {torch.__version__}&#39;); print(f&#39;PyTorch CUDA version: {torch.version.cuda}&#39;)</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 同时检查 conda 环境中 PyTorch 的构建信息</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">mamba</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> list</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;"> |</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> grep</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> pytorch</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>nvcc</code> 版本与 <code>torch.version.cuda</code> 以及 <code>mamba list</code> 中 <code>pytorch-cuda</code> 包指示的版本都是 <code>cuda11.8</code>，没问题啊！</p><p><strong>问题发现：</strong></p><p>当使用 <code>pip install -e .</code> 配合 <code>pyproject.toml</code> 文件时，<code>pip</code> 会创建一个隔离的构建环境，并根据 <code>pyproject.toml</code> 中的 <code>build-system.requires</code> 安装构建依赖。如果这里声明的 <code>torch</code> 版本比较宽松（如 <code>torch&gt;=2.0</code>），<u><code>pip</code> 可能会从 PyPI 拉取一个与你当前 Conda 环境中 PyTorch CUDA 版本不匹配的 <code>torch</code></u>（例如，拉取了一个为 CUDA 12.x 编译的 PyTorch）</p><hr><p><strong>解决方案：</strong></p><p>在 <code>map4d</code> 项目的 <code>pyproject.toml</code> 文件中，明确指定 <code>build-system.requires</code> 下的 <code>torch</code> 版本，使其与你 Conda 环境中的 <code>torch</code> 版本和 CUDA 版本严格一致。比如 Conda 环境是 PyTorch 2.0.1 for CUDA 11.8：</p><div class="language-toml line-numbers-mode" data-highlighter="shiki" data-ext="toml" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># pyproject.toml</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">build-system</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">requires</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> [</span></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">	    	# ...</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">    &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">torch==2.0.1</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"> # 确保与环境一致</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">build-backend</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">setuptools.build_meta</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># ...</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>修改之后，再执行 <code>python setup.py develop</code> 就没问题了！🫡</p><h2 id="_1-11-3-unknown-cuda-arch-x-y-or-gpu-not-supported" tabindex="-1"><a class="header-anchor" href="#_1-11-3-unknown-cuda-arch-x-y-or-gpu-not-supported"><span>1.11.3 Unknown CUDA arch (X.Y) or GPU not supported</span></a></h2><p>依然是在使用 <code>pip install -e .</code> / <code>python setup.py develop</code> 安装 <code>map4d</code> 时，在编译 CUDA 扩展时，遇到如下错误：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">File</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">.../torch/utils/cpp_extension.py</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">,</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> line</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ...,</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> in</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> _get_cuda_arch_flags</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">    raise</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ValueError</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">f</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">&quot;Unknown CUDA arch ({arch}) or GPU not supported&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">ValueError:</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> Unknown</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> CUDA</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> arch</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> (10.0) or GPU not supported</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>这个错误意味着 PyTorch 的构建系统在尝试为特定的 CUDA GPU 计算架构 (Compute Capability, 如 7.5, 8.6) 生成编译器标志 (如 <code>-gencode arch=compute_86,code=sm_86</code>) 时，遇到了一个无法识别的架构代号，比如 &quot;10.0&quot;。这些架构代号通常通过环境变量 <code>TORCH_CUDA_ARCH_LIST</code> 指定，或者由 PyTorch 自动检测。错误中出现的 &quot;10.0&quot;, &quot;10.1&quot;, &quot;12.0&quot; 等都不是有效的 CUDA 计算架构版本号，它们可能被错误地从 CUDA <em>Toolkit 版本号</em> (如 CUDA Toolkit 10.0, 12.0) 混淆而来</p></blockquote><p><strong>检查 <code>TORCH_CUDA_ARCH_LIST</code> 环境变量:</strong> 这是最常见的肇事者</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">echo</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> $TORCH_CUDA_ARCH_LIST</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">5.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">5.2</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">6.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">6.1</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">7.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">7.5</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">8.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">8.6</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">8.9</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">9.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">10.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">10.1</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">10.3</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">12.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">12.1+PTX</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>果然输出一大堆，解决方法很简单：<strong>清空该环境变量</strong>，最简单的方法是清空此环境变量。PyTorch 会自动检测当前机器上 GPU 的架构并为其编译</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">unset</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> TORCH_CUDA_ARCH_LIST</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>但是注意：这样在之后的运行中发现，会导致 tinycudann 只能在卡 0 运行（因为这台服务器的卡 0 不太一样，是 4090，其他的卡是 3090），所以推荐找到自己卡的 Compute Capability：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">export</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> TORCH_CUDA_ARCH_LIST</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">8.6;8.9+PTX</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div>`,24))])}const y=n(r,[["render",o]]),u=JSON.parse(`{"path":"/experience/uq1zai1j/","title":"1.11 Map4D","lang":"zh-CN","frontmatter":{"title":"1.11 Map4D","createTime":"2025/05/13 21:12:20","permalink":"/experience/uq1zai1j/","description":"1.11.1 tiny-cuda-nn tiny-cuda-nn 的编译问题见 1.11.2 CUDA 版本不匹配 在使用 pip install -e . / python setup.py develop 安装 map4d 或其他依赖 PyTorch C++/CUDA 扩展的包时，遇到了以下的错误： 排查： nvcc 版本与 torch.versi...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"1.11 Map4D\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-05-13T13:14:36.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://plus-wave.github.io/experience/uq1zai1j/"}],["meta",{"property":"og:site_name","content":"PLUS-WAVE's Blog"}],["meta",{"property":"og:title","content":"1.11 Map4D"}],["meta",{"property":"og:description","content":"1.11.1 tiny-cuda-nn tiny-cuda-nn 的编译问题见 1.11.2 CUDA 版本不匹配 在使用 pip install -e . / python setup.py develop 安装 map4d 或其他依赖 PyTorch C++/CUDA 扩展的包时，遇到了以下的错误： 排查： nvcc 版本与 torch.versi..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-05-13T13:14:36.000Z"}],["meta",{"property":"article:modified_time","content":"2025-05-13T13:14:36.000Z"}]]},"readingTime":{"minutes":2.4,"words":721},"git":{"updatedTime":1747142076000,"contributors":[{"name":"PLUS_WAVE","username":"","email":"wangplus_wave@foxmail.com","commits":1,"avatar":"https://gravatar.com/avatar/73d9cce6b7473bc4e3bccd9c674dc373250f563551d205366d1b3852d719f74e?d=retro"}]},"autoDesc":true,"filePathRelative":"notes/Experience/1. Environment/2.2 Map4D.md","headers":[]}`);export{y as comp,u as data};
