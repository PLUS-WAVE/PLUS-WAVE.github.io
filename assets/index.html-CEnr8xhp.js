import{_ as a,c as i,e as t,o as n}from"./app-CGJJd-cj.js";const e={};function l(p,s){return n(),i("div",null,s[0]||(s[0]=[t(`<h3 id="_1-sad法计算图像的视差图" tabindex="-1"><a class="header-anchor" href="#_1-sad法计算图像的视差图"><span>1 SAD法计算图像的视差图</span></a></h3><p>视差图：以左视图视差图为例，在像素位置p的视差值等于该像素在右图上的匹配点的列坐标减去其在左图上的列坐标</p><p>视差图和深度图：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>z</mi><mo>=</mo><mfrac><mrow><mi>f</mi><mi>b</mi></mrow><mi>d</mi></mfrac></mrow><annotation encoding="application/x-tex">z = \\frac{fb}{d} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span> 是视差， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> 是焦距， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> 是基线长度</p><img src="https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-22/image-20240322211454831.png" alt="image-20240322211454831" style="zoom:50%;"><p>所以，<strong>视差越大 ——&gt; 深度越小</strong></p><h4 id="_1-1-传统方法" tabindex="-1"><a class="header-anchor" href="#_1-1-传统方法"><span>1.1 传统方法</span></a></h4><p>原理：是在给定窗口大小的情况下，对左图像和右图像的对应窗口进行比较，计算它们之间的绝对差的总和，从而确定最佳匹配的视差</p><p><strong>SAD</strong>：Sum of Absolute Differences 即差的绝对值和</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mi>A</mi><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∣</mi><msub><mi>w</mi><mi>L</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>−</mo><msub><mi>w</mi><mi>R</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>d</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">SAD(x,y,d) = |w_L(x, y) - w_R(x-d, y)| </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord">∣</span></span></span></span></span></p><p>大致流程：</p><ol><li><p>对左图像和右图像分别进行<strong>零填充</strong>以适应窗口的边界</p><blockquote><p>为在计算这些像素的视差时，窗口可能会超出图像的范围</p></blockquote></li><li><p>对于左图像的每个像素，依次遍历整个图像</p></li><li><p>对于每个像素，以其为中心取窗口大小的区域，并在右图像中<strong>搜索匹配窗口</strong></p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 一定是减去d，因为右边图像是左边图像向右平移d个像素</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">window_right </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> image_right</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">+</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> window_size</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">-</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> d</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">-</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> d </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">+</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> window_size</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>设置一个 <code>max_disparity</code> 来限制搜索范围</p></blockquote></li><li><p>计算左图像窗口和右图像匹配窗口的绝对差的总和，即SAD值</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">now_sad </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> np</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">sum</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">np</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">abs</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">window_left </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">-</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> window_right</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li><p>找到最小的SAD值，将对应的视差 <code>d</code> 保存到该像素位置</p></li></ol><h4 id="_1-2-卷积方法" tabindex="-1"><a class="header-anchor" href="#_1-2-卷积方法"><span>1.2 卷积方法</span></a></h4><p>利用图像卷积的思想，通过对每个候选视差值计算绝对差图像，并将其与一个均值滤波器进行卷积操作来实现视差图的计算</p><p>具体步骤如下：</p><ol><li><p>对于每个候选的视差值，计算两幅图像在水平方向上的绝对差</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">img_diff </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> np</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">abs</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">image_left </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">-</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> right_shifted</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li><p>将计算得到的绝对差图像与一个均值滤波器进行卷积操作。均值滤波器的大小应与窗口大小相匹配，用于平滑绝对差图像，从而减少噪声和不稳定性</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 平滑均值滤波卷积核</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">kernel </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> np</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ones</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">((</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">window_size</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> window_size</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">))</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;"> /</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> (</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">window_size </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">**</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 2</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 通过卷积运算，可以计算出每个像素邻域的总差异，也就是SAD值</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">img_sad </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> convolve</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">img_diff</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> kernel</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> mode</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">same</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>卷积的作用：</p><ol><li>平滑处理：卷积可以用来对图像进行平滑处理，也就是降噪。当卷积核是一个均值滤波器，就可以用于计算图像中每个像素的邻域的平均值。这样可以减少图像中的随机噪声，使图像变得更加平滑</li><li>计算局部差异：在计算左图和右图之间的 SAD 值时，需要对每个像素的邻域进行操作。这可以通过卷积来实现。卷积结果中的每个像素值表示了对应的<strong>像素邻域</strong>在左图和右图之间的差异程度</li></ol></blockquote></li><li><p>对于每个像素，选择具有最小卷积结果的视差值作为最终的视差值</p></li></ol><h4 id="_1-3-问题" tabindex="-1"><a class="header-anchor" href="#_1-3-问题"><span>1.3 问题</span></a></h4><p>块匹配方法在处理时存在一些限制，主要包括以下几点：</p><ol><li><p>局部窗口匹配：块匹配方法通常只考虑局部窗口内的像素信息进行匹配，而对于同质区域，局部窗口内的<strong>像素可能非常相似</strong>，导致匹配困难</p></li><li><p>窗口大小选择：选择合适的窗口大小对于块匹配的性能至关重要。</p><ul><li>小窗口：在<strong>纹理丰富</strong>的区域，可以选择较小的窗口；但对于同质区域可能无法捕捉到同质区域的整体特征</li><li>大窗口：<strong>纹理稀疏</strong>的区域，应选择较大的窗口大小；但可能会将不同物体的特征混合在一起，导致误匹配，但在较大的窗口大小会<strong>增加计算量</strong></li></ul><table><thead><tr><th>窗口大小</th><th>结果</th></tr></thead><tbody><tr><td>3</td><td><img src="https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323095500779.png" alt="image-20240323095500779" loading="lazy"></td></tr><tr><td>7</td><td><img src="https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323095545339.png" alt="image-20240323095545339" loading="lazy"></td></tr><tr><td>15</td><td><img src="https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323095611812.png" alt="image-20240323095611812" loading="lazy"></td></tr></tbody></table></li></ol><h3 id="_2-siamese神经网络" tabindex="-1"><a class="header-anchor" href="#_2-siamese神经网络"><span>2 Siamese神经网络</span></a></h3><p>Siamese神经网络由两个相同的子网络组成，这两个子网络共享相同的参数（权重和偏置）。无论输入是什么，它们都会通过相同的网络结构进行处理</p><ol><li><strong>特征提取</strong>：给定两个输入，它们分别通过两个子网络进行前向传播，从而得到它们的特征表示。这些特征表示捕捉了输入的关键信息</li><li><strong>相似性评估</strong>：得到特征表示后，Siamese神经网络通过某种方式比较这两个特征表示，以确定它们之间的相似性。我们使用余弦相似度来操作</li></ol><p>其有两种结构：</p><ol><li><p><strong>余弦相似度 (Cosine Similarity)</strong>：</p><p><img src="https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323152419080.png" alt="" loading="lazy"></p><ul><li>原理：计算两个特征向量之间的夹角余弦值，范围在-1到1之间。值越接近1，表示两个向量越相似；值越接近-1，表示两个向量越不相似；值接近0表示两个向量之间没有线性关系</li><li>应用：通过计算特征向量之间的余弦相似度，可以衡量它们在特征空间中的方向是否相似，其没有MLP，卷积层后直接标准化进行点乘，速度非常快，且效果也较好</li></ul></li><li><p><strong>学习相似性 (Learned Similarity)</strong>：</p><p><img src="https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323152802625.png" alt="image-20240323152802625" loading="lazy"></p><ul><li>原理：需要训练一个神经网络，该网络将输入的特征向量映射到一个标量值，表示它们之间的相似性得分</li><li>应用：神经网络可以学习到更复杂的特征表示，并且可以捕捉输入之间的非线性关系。但是，由于MLP的计算成本较高，会较于前者较慢</li></ul></li></ol>`,25)]))}const r=a(e,[["render",l]]),m=JSON.parse(`{"path":"/3dv/f4yj2ywp/","title":"ex2-2 Stereo Reconstruction","lang":"zh-CN","frontmatter":{"title":"ex2-2 Stereo Reconstruction","createTime":"2024/11/24 15:34:21","permalink":"/3dv/f4yj2ywp/","description":"1 SAD法计算图像的视差图 视差图：以左视图视差图为例，在像素位置p的视差值等于该像素在右图上的匹配点的列坐标减去其在左图上的列坐标 视差图和深度图： z=dfb​ 其中 d 是视差， f 是焦距， b 是基线长度 image-20240322211454831 所以，视差越大 ——> 深度越小 1.1 传统方法 原理：是在给定窗口大小的情况下，对左...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ex2-2 Stereo Reconstruction\\",\\"image\\":[\\"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323095500779.png\\",\\"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323095545339.png\\",\\"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323095611812.png\\",\\"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323152419080.png\\",\\"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323152802625.png\\"],\\"dateModified\\":\\"2024-11-24T08:08:35.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://plus-wave.github.io/3dv/f4yj2ywp/"}],["meta",{"property":"og:site_name","content":"PLUS-WAVE's Blog"}],["meta",{"property":"og:title","content":"ex2-2 Stereo Reconstruction"}],["meta",{"property":"og:description","content":"1 SAD法计算图像的视差图 视差图：以左视图视差图为例，在像素位置p的视差值等于该像素在右图上的匹配点的列坐标减去其在左图上的列坐标 视差图和深度图： z=dfb​ 其中 d 是视差， f 是焦距， b 是基线长度 image-20240322211454831 所以，视差越大 ——> 深度越小 1.1 传统方法 原理：是在给定窗口大小的情况下，对左..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2024-03-23/image-20240323095500779.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-11-24T08:08:35.000Z"}],["meta",{"property":"article:modified_time","content":"2024-11-24T08:08:35.000Z"}]]},"readingTime":{"minutes":5.04,"words":1512},"git":{"updatedTime":1732435715000,"contributors":[{"name":"PLUS_WAVE","username":"","email":"wangplus_wave@foxmail.com","commits":2,"avatar":"https://gravatar.com/avatar/73d9cce6b7473bc4e3bccd9c674dc373250f563551d205366d1b3852d719f74e?d=retro"}]},"autoDesc":true,"filePathRelative":"notes/3DV Course/3DV Course/3. ex2-2 Stereo Reconstruction.md","headers":[]}`);export{r as comp,m as data};
