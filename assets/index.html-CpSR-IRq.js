import{_ as a,c as t,e as n,o as p}from"./app-CGJJd-cj.js";const e={};function l(i,s){return p(),t("div",null,s[0]||(s[0]=[n(`<h2 id="_1-motivation" tabindex="-1"><a class="header-anchor" href="#_1-motivation"><span>1 Motivation</span></a></h2><p><a href="https://arxiv.org/abs/2402.04236" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2402.04236</a></p><p>当前 VLMs 通过对齐视觉输入和语言输出训练，虽然整体表现好，但在需要<strong>细致视觉推理</strong>的任务上容易出错，比如无法正确识别图片中的细节内容。这是因为现有模型习惯直接给出结论，而缺乏中间推理步骤。</p><p>人类解决视觉问题时，会<strong>逐步操作</strong>（比如圈出目标、放大细节区域），不是直接回答。</p><p>方法：<strong>Chain of Manipulations (CoM)</strong></p><ul><li>让模型自己一步步处理图像（比如：标注区域、放大、裁剪等），并在每一步输出中间结果（比如 bbox、生成局部图像）。</li></ul><h2 id="_2-method" tabindex="-1"><a class="header-anchor" href="#_2-method"><span>2 Method</span></a></h2><h3 id="_2-1-基本操作" tabindex="-1"><a class="header-anchor" href="#_2-1-基本操作"><span>2.1 基本操作</span></a></h3><p>做了一个实验：</p><ul><li>用 GPT-4 自动生成解决图像问题的步骤，允许它在需要时对图片做操作</li><li>处理了 170K 个 TextVQA 问题（需要细粒度视觉推理的数据集）</li><li>提供了4个手写示例给GPT-4作为指导，保证生成质量</li><li>然后用 StanfordCoreNLP 提取回答中的动词短语（表示操作动作）</li></ul><p>通过频率统计，发现绝大多数动作可以归结为<strong>6种基本操作</strong>：</p><table><thead><tr><th>操作名称</th><th>功能描述</th></tr></thead><tbody><tr><td><strong>OCR(tgt) → txt</strong></td><td>识别目标区域（tgt）的文字，输出文字（txt）</td></tr><tr><td><strong>Grounding(tgt) → bbx</strong></td><td>找到目标（tgt）的定位框（bounding box）</td></tr><tr><td><strong>Counting(tgt) → num</strong></td><td>数目标（tgt）的数量，输出数字（num）</td></tr><tr><td><strong>Calculate(tgt) → num</strong></td><td>对目标（tgt）进行计算，输出数字（num）</td></tr><tr><td><strong>CropZoomIn(bbx, x) → img</strong></td><td>按比例(x)放大或裁剪bbx区域，输出局部图片（img）</td></tr><tr><td><strong>Line(pts) → img</strong></td><td>在图片上画线（连接指定的点pts），输出新的图像（img）</td></tr></tbody></table><h3 id="_2-2-数据收集" tabindex="-1"><a class="header-anchor" href="#_2-2-数据收集"><span>2.2 数据收集</span></a></h3><img src="https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2025-04-27/image-20250426201619675.png" alt="image-20250426201619675" style="zoom:50%;"><p>基于普通VQA数据集 {(I, Q, A)}，自动生成标准的CoM样本（特别是数学问题领域再结合人工标注）</p><p>📌<strong>自动流程</strong>：</p><ol><li><p>LLM 生成语言推理链：让 GPT-4 生成带操作的推理链（结果用变量占位）</p></li><li><p>VFM（GroundingDINO、PaddleOCR） 执行视觉操作补全结果</p><blockquote><p>大部分操作都可以基于 <strong>Grounding</strong> 和 <strong>OCR</strong> 衍生：</p><ul><li>CropZoomIn → 基于 Grounding 的框来裁剪</li><li>Counting → 基于检测的box数量</li><li>Calculate → 基于OCR识别出的公式</li></ul></blockquote></li><li><p>DFS 搜索正向推理路径（最后得到正确答案A）</p></li></ol><p>📌<strong>人工数据集</strong>：</p><p><strong>图形数学题</strong>（如几何推理、图表阅读），需要更精准的辅助线绘制、公式推导。受启发于 AlphaGeometry，发现辅助线（或中间推理步骤）能显著帮助 LLMs 解复杂数学问题。招募了10位人类专家，手动完成：约 7K 高质量 CoM 数学样本</p><ul><li>语言推理步骤</li><li>操作名称的使用</li><li>操作结果（图像或数值）</li></ul><h2 id="_3-model" tabindex="-1"><a class="header-anchor" href="#_3-model"><span>3 Model</span></a></h2><h3 id="_3-1-architecture-模型架构" tabindex="-1"><a class="header-anchor" href="#_3-1-architecture-模型架构"><span>3.1 ARCHITECTURE （模型架构）</span></a></h3><p>整体框架采用 CogVLM 的通用VLM架构，包括四个核心组件：</p><ol><li><strong>Visual Encoder</strong>：视觉编码器</li><li><strong>MLP Adapter</strong>：把视觉特征映射到语言空间</li><li><strong>LLM Backbone</strong>：大型语言模型骨干</li><li><strong>Visual Expert Module</strong>：视觉专家模块（深度融合视觉特征）</li></ol><table><thead><tr><th>组件</th><th>使用的模型</th><th>说明</th></tr></thead><tbody><tr><td>Visual Encoder</td><td>EVA2-CLIP-E (4B参数)</td><td>视觉特征提取</td></tr><tr><td>LLM Backbone</td><td>Vicuna-7B-v1.5</td><td>语言理解与生成</td></tr><tr><td>MLP Adapter</td><td>两层 SwiGLU MLP</td><td>映射视觉到语言空间</td></tr><tr><td>Visual Expert Module</td><td>加到 LLM 每层的注意力和 FFN 里</td><td>额外增加6.5B参数</td></tr></tbody></table><p>整体规模大约 17B参数（7B + 4B + 6.5B）</p><img src="https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2025-04-27/image-20250426203150300.png" alt="image-20250426203150300" style="zoom:50%;"><p>多轮推理机制（Memory-based Multi-turn Multi-image）?</p><ul><li>支持处理多轮VQA样本： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msub><mi>I</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>Q</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>A</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi>t</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[(I_t, Q_t, A_t)|t = 1,2,...]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∣</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mclose">]</span></span></span></span></li><li><strong>KV缓存</strong>（Key-Value Memories）在每一层持续累积。</li><li>每轮 attention 计算公式（按累积KV）：</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>att</mtext><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>Q</mi><mi>t</mi></msub><msubsup><mi>K</mi><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msup><mrow></mrow><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo fence="true">)</mo></mrow><msubsup><mi>V</mi><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\\text{att}(X) = \\text{softmax}\\left( \\frac{Q_t K&#39;_t{}^T}{\\sqrt{d}} \\right) V&#39;_t </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">att</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4684em;vertical-align:-0.95em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.1778em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">d</span></span></span><span style="top:-2.8922em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1078em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.453em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-2.453em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p><h3 id="_3-2-training" tabindex="-1"><a class="header-anchor" href="#_3-2-training"><span>3.2 Training</span></a></h3><p>📌 第一阶段 Pre-Training</p><ul><li>步骤一：视觉理解 <ul><li>数据：1.5B对图文对（清洗自 LAION-2B 和 COYO-700M）</li><li>训练：120K step，batch size 8192</li></ul></li><li>步骤二：定位生成（Grounded Generation） <ul><li>数据：40M条图像-问题-答案三元组（清洗自 LAION-115M）</li><li>训练：60K step，batch size 1024</li><li>答案中每个名词短语都配了位置坐标 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo stretchy="false">[</mo><mi>x</mi><mn>0</mn><mo separator="true">,</mo><mi>y</mi><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mn>1</mn><mo separator="true">,</mo><mi>y</mi><mn>1</mn><mo stretchy="false">]</mo><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[[x0,y0,x1,y1],...]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[[</span><span class="mord mathnormal">x</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord">1</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mclose">]</span></span></span></span></li></ul></li></ul><p>这阶段主要训练的是视觉专家模块（6.5B参数）。</p><hr><p>📌 第二阶段 Alignment</p><p>将CoM数据与其他三类数据混合训练：MultiInstruct（指令跟随能力）、LLaVAR（识别文本能力）、ShareGPT4V（细粒度描述能力）</p><p>总融合得到大约 570K条(I, Q, A)样本。</p><ul><li>其中 CoM 样本是多轮式的答案（包含推理链）</li><li>对 CoM 样本，还会在问题前随机加触发prompt <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>M</mi></msub></mrow><annotation encoding="application/x-tex">P_M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，提示模型可以主动使用 manipulation 推理</li></ul><p>训练：14K step，batch size 160，warm-up 280步，最高学习率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span>，然后线性下降。</p><p>这阶段也是只训练视觉专家模块（6.5B参数）</p><p>这阶段也是只训练视觉专家模块（6.5B参数）</p><hr><p>我理解的 inference 过程，设输入如下：</p><div class="language-css line-numbers-mode" data-highlighter="shiki" data-ext="css" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">图像：一张表格图片</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Q：请问“销售额最高的月份”是哪一个？</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol><li>理解任务类型：识别出这是一道“图表+文本识别+比较”的视觉问题；</li><li>判断需要信息获取：知道不能直接回答，需要先读取图表；</li><li>使用 manipulation： <ul><li>先用 OCR 提取文本</li><li>再识别最大值</li><li>最后输出答案</li></ul></li></ol><hr><p>确定当前情况是要做什么操作呢？</p><ol><li>CoM 数据中已经通过“多轮+操作序列”的方式示范如何一步步推理</li><li>多轮上下文累积（KV memory）：保持上下文，让模型知道当前已做了什么、接下来该做什么；多轮结构下，模型具备上下文感知能力</li></ol>`,49)]))}const r=a(e,[["render",l]]),o=JSON.parse(`{"path":"/article/s1aillrh/","title":"CogCoM 学习笔记","lang":"zh-CN","frontmatter":{"title":"CogCoM 学习笔记","tags":["CV","VLM","Reasoning"],"createTime":"2025/04/27 09:58:20","permalink":"/article/s1aillrh/","cover":"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2025-04-27/image-20250426201619675.png","description":"1 Motivation https://arxiv.org/abs/2402.04236 当前 VLMs 通过对齐视觉输入和语言输出训练，虽然整体表现好，但在需要细致视觉推理的任务上容易出错，比如无法正确识别图片中的细节内容。这是因为现有模型习惯直接给出结论，而缺乏中间推理步骤。 人类解决视觉问题时，会逐步操作（比如圈出目标、放大细节区域），不是直接...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CogCoM 学习笔记\\",\\"image\\":[\\"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2025-04-27/image-20250426201619675.png\\"],\\"dateModified\\":\\"2025-05-07T02:19:51.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://plus-wave.github.io/article/s1aillrh/"}],["meta",{"property":"og:site_name","content":"PLUS-WAVE's Blog"}],["meta",{"property":"og:title","content":"CogCoM 学习笔记"}],["meta",{"property":"og:description","content":"1 Motivation https://arxiv.org/abs/2402.04236 当前 VLMs 通过对齐视觉输入和语言输出训练，虽然整体表现好，但在需要细致视觉推理的任务上容易出错，比如无法正确识别图片中的细节内容。这是因为现有模型习惯直接给出结论，而缺乏中间推理步骤。 人类解决视觉问题时，会逐步操作（比如圈出目标、放大细节区域），不是直接..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2025-04-27/image-20250426201619675.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-05-07T02:19:51.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://raw.githubusercontent.com/PLUS-WAVE/blog-image/master/img/blog/2025-04-27/image-20250426201619675.png"}],["meta",{"name":"twitter:image:alt","content":"CogCoM 学习笔记"}],["meta",{"property":"article:tag","content":"Reasoning"}],["meta",{"property":"article:tag","content":"VLM"}],["meta",{"property":"article:tag","content":"CV"}],["meta",{"property":"article:modified_time","content":"2025-05-07T02:19:51.000Z"}]]},"readingTime":{"minutes":4.8,"words":1441},"git":{"updatedTime":1746584391000,"contributors":[{"name":"PLUS_WAVE","username":"","email":"wangplus_wave@foxmail.com","commits":3,"avatar":"https://gravatar.com/avatar/73d9cce6b7473bc4e3bccd9c674dc373250f563551d205366d1b3852d719f74e?d=retro"}]},"autoDesc":true,"filePathRelative":"2. CV/24. CogCoM_Note.md","headers":[],"categoryList":[{"id":"de90e8","sort":2,"name":" CV"}]}`);export{r as comp,o as data};
