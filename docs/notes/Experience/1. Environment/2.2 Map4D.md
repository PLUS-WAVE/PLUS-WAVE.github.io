---
title: 1.11 Map4D
createTime: 2025/05/13 21:12:20
permalink: /experience/uq1zai1j/
---
## 1.11.1 tiny-cuda-nn

tiny-cuda-nn 的编译问题见 [1.2.7 ld: cannot find -lcuda](/experience/a5k8sy7u/#_1-2-7-ld-cannot-find-lcuda)

## 1.11.2 CUDA 版本不匹配

在使用 `pip install -e .` / `python setup.py develop` 安装 `map4d` 或其他依赖 PyTorch C++/CUDA 扩展的包时，遇到了以下的错误：

```bash
RuntimeError:
The detected CUDA version (11.8) mismatches the version that was used to compile
PyTorch (12.4). Please make sure to use the same CUDA versions.
```

---

**排查：**

```bash
nvcc --version
python -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'PyTorch CUDA version: {torch.version.cuda}')"
# 同时检查 conda 环境中 PyTorch 的构建信息
mamba list | grep pytorch
```

`nvcc` 版本与 `torch.version.cuda` 以及 `mamba list` 中 `pytorch-cuda` 包指示的版本都是 `cuda11.8`，没问题啊！

**问题发现：**

当使用 `pip install -e .` 配合 `pyproject.toml` 文件时，`pip` 会创建一个隔离的构建环境，并根据 `pyproject.toml` 中的 `build-system.requires` 安装构建依赖。如果这里声明的 `torch` 版本比较宽松（如 `torch>=2.0`），<u>`pip` 可能会从 PyPI 拉取一个与你当前 Conda 环境中 PyTorch CUDA 版本不匹配的 `torch`</u>（例如，拉取了一个为 CUDA 12.x 编译的 PyTorch）

---

**解决方案：**

在 `map4d` 项目的 `pyproject.toml` 文件中，明确指定 `build-system.requires` 下的 `torch` 版本，使其与你 Conda 环境中的 `torch` 版本和 CUDA 版本严格一致。比如 Conda 环境是 PyTorch 2.0.1 for CUDA 11.8：

```toml
# pyproject.toml
[build-system]
requires = [
	    	# ...
    "torch==2.0.1", # 确保与环境一致
]
build-backend = "setuptools.build_meta"
# ...
```

修改之后，再执行 `python setup.py develop` 就没问题了！🫡

## 1.11.3 Unknown CUDA arch (X.Y) or GPU not supported

依然是在使用 `pip install -e .` / `python setup.py develop` 安装 `map4d` 时，在编译 CUDA 扩展时，遇到如下错误：

```bash
File ".../torch/utils/cpp_extension.py", line ..., in _get_cuda_arch_flags
    raise ValueError(f"Unknown CUDA arch ({arch}) or GPU not supported")
ValueError: Unknown CUDA arch (10.0) or GPU not supported
```

> 这个错误意味着 PyTorch 的构建系统在尝试为特定的 CUDA GPU 计算架构 (Compute Capability, 如 7.5, 8.6) 生成编译器标志 (如 `-gencode arch=compute_86,code=sm_86`) 时，遇到了一个无法识别的架构代号，比如 "10.0"。这些架构代号通常通过环境变量 `TORCH_CUDA_ARCH_LIST` 指定，或者由 PyTorch 自动检测。错误中出现的 "10.0", "10.1", "12.0" 等都不是有效的 CUDA 计算架构版本号，它们可能被错误地从 CUDA *Toolkit 版本号* (如 CUDA Toolkit 10.0, 12.0) 混淆而来

**检查 `TORCH_CUDA_ARCH_LIST` 环境变量:** 这是最常见的肇事者

```bash
echo $TORCH_CUDA_ARCH_LIST
5.0;5.2;6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0;10.0;10.1;10.3;12.0;12.1+PTX
```

果然输出一大堆，解决方法很简单：**清空该环境变量**，最简单的方法是清空此环境变量。PyTorch 会自动检测当前机器上 GPU 的架构并为其编译

```bash
unset TORCH_CUDA_ARCH_LIST
```

但是注意：这样在之后的运行中发现，会导致 tinycudann 只能在卡 0 运行（因为这台服务器的卡 0 不太一样，是 4090，其他的卡是 3090），所以推荐找到自己卡的 Compute Capability：

```bash
export TORCH_CUDA_ARCH_LIST="8.6;8.9+PTX"
```

